{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: before completing this step, the following steps should be run:\n",
    "* ChicagoPDData notebook\n",
    "* make all in main directory\n",
    "* make all in AoT_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_dir = 'AoT_data/'\n",
    "# node_loc_list = pd.read_csv(a_dir+'node_loc_list.csv',index_col=0)\n",
    "# full_data= pd.read_csv(a_dir+'fixed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_crime_dict():\n",
    "    crime_dict = {}\n",
    "    with open('final_dat.csv','r') as file:\n",
    "        for line in file:\n",
    "            curr_line=line.strip().split(',')\n",
    "            if curr_line[0] not in crime_dict.keys():\n",
    "                crime_dict[curr_line[0]]={'coords':[]}\n",
    "            crime_dict[curr_line[0]]['coords'].append((float(curr_line[2]),float(curr_line[1])))\n",
    "    return crime_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crime_dict=create_crime_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# full_data =full_data.loc[full_data['parameter']!='id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_data.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(crime_data.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(crime_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_loc_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a very large amount of data to handle here, so dictionaries are used for speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#node_dict=node_loc_list.to_dict('index')\n",
    "#full_list=full_data.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below takes a list version of the full data (obtained from full_data.values.tolist()) and converts it to a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_dict(full_list,node_dict):\n",
    "    full_dict={}\n",
    "    for index,row in enumerate(full_list):\n",
    "        timestamp=row[0][0:13]\n",
    "        node_id=row[1]\n",
    "        full_id = str(timestamp)+'_'+str(node_id)\n",
    "        feature_name = str(row[3])+'_'+str(row[4])\n",
    "        value=row[5]\n",
    "        node_lat=node_dict[node_id]['lat']\n",
    "        node_lon=node_dict[node_id]['lon']\n",
    "        if not full_id in full_dict.keys():\n",
    "            full_dict[full_id]={}\n",
    "        full_dict[full_id][feature_name]=value\n",
    "        full_dict[full_id]['timestamp']=timestamp\n",
    "        full_dict[full_id]['node_id']=node_id\n",
    "        full_dict[full_id]['latitude']=node_lat\n",
    "        full_dict[full_id]['longitude']=node_lon\n",
    "    return full_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_full_dict(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# len(full_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(full_dict,crime_dict,max_dist=2):\n",
    "    for id in full_dict.keys():\n",
    "        label=0\n",
    "        timestamp=full_dict[id]['timestamp']\n",
    "        node_lat=full_dict[id]['latitude']\n",
    "        node_lon=full_dict[id]['longitude']\n",
    "        if timestamp in crime_dict.keys():\n",
    "            crime_coords=crime_dict[timestamp]['coords']\n",
    "            label = crime_occurrence_check((node_lat,node_lon),crime_coords,max_dist)\n",
    "        full_dict[id]['label']=label\n",
    "    return full_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#next(iter(full_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the function below is not mine, it is pulled from [https://stackoverflow.com/questions/15736995/how-can-i-quickly-estimate-the-distance-between-two-latitude-longitude-points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    # Radius of earth in kilometers is 6371\n",
    "    km = 6371* c\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crime_occurrence_check(node_coords,crime_coods_list,max_dist=2):\n",
    "    crime_occurred=0\n",
    "    for crime_coord in crime_coods_list:\n",
    "        if haversine(node_coords[1],node_coords[0],crime_coord[1],crime_coord[0]) < max_dist:\n",
    "            crime_occurred=1\n",
    "            return crime_occurred\n",
    "    return crime_occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_data = pd.DataFrame.from_dict(full_dict,orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To decide an appropriate value for max_dist, let's look at the average minimum distance between the current nodes. We choose this statistic, as it means on average, the closest node is that far away. Thus, by assigning crimes only if they are less than this distance, we will on average only assign the crime to the closest node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "def find_avg_node_dist(node_loc_list):\n",
    "    distance_avgs=[]\n",
    "    for index,row in node_loc_list.iterrows():\n",
    "        base_lat=row[0]\n",
    "        base_lon=row[1]\n",
    "        distances=[]\n",
    "        for index2,row2 in node_loc_list.iterrows():\n",
    "            if index != index2:\n",
    "                distances.append(haversine(base_lon,base_lat,row2[1],row2[0]))  \n",
    "        distance_avgs.append(min([x for x in distances if x>0]))\n",
    "    return math.ceil(statistics.mean(distance_avgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 km\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "a_dir = 'AoT_data/'\n",
    "node_loc_list = pd.read_csv(a_dir+'node_loc_list.csv',index_col=0)\n",
    "max_dist = math.ceil(find_avg_node_dist(node_loc_list))\n",
    "print(max_dist,\"km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_set():\n",
    "    a_dir = 'AoT_data/'\n",
    "    node_loc_list = pd.read_csv(a_dir+'node_loc_list.csv',index_col=0)\n",
    "    max_dist = math.ceil(find_avg_node_dist(node_loc_list))\n",
    "    full_data= pd.read_csv(a_dir+'fixed_data.csv')\n",
    "    full_data =full_data.loc[full_data['parameter']!='id']\n",
    "    full_list=full_data.values.tolist()\n",
    "    node_dict=node_loc_list.to_dict('index')\n",
    "    full_dict=get_full_dict(full_list,node_dict)\n",
    "    crime_dict=create_crime_dict()\n",
    "    full_dict=add_labels(full_dict,crime_dict,max_dist)\n",
    "    labeled_data = pd.DataFrame.from_dict(full_dict,orient='index')\n",
    "    return labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 127.46793913841248 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# NOTE: This cell takes around 2 minutes to run but does all of the data preprocessing\n",
    "import time\n",
    "start=time.time()\n",
    "labeled_data=get_full_set()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(546257, 145)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>latitude</th>\n",
       "      <th>label</th>\n",
       "      <th>tsl250rd_intensity</th>\n",
       "      <th>pr103j2_temperature</th>\n",
       "      <th>node_id</th>\n",
       "      <th>hih4030_humidity</th>\n",
       "      <th>longitude</th>\n",
       "      <th>spv1840lr5h_b_intensity</th>\n",
       "      <th>mlx75305_intensity</th>\n",
       "      <th>...</th>\n",
       "      <th>microphone_octave_6_intensity</th>\n",
       "      <th>microphone_octave_8_intensity</th>\n",
       "      <th>microphone_octave_9_intensity</th>\n",
       "      <th>net_usb_rx</th>\n",
       "      <th>microphone_octave_7_intensity</th>\n",
       "      <th>microphone_octave_5_intensity</th>\n",
       "      <th>microphone_octave_3_intensity</th>\n",
       "      <th>microphone_octave_1_intensity</th>\n",
       "      <th>microphone_octave_2_intensity</th>\n",
       "      <th>microphone_octave_10_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017/03/28 17_001e0610ba46</th>\n",
       "      <td>2017/03/28 17</td>\n",
       "      <td>41.878377</td>\n",
       "      <td>1</td>\n",
       "      <td>1.639</td>\n",
       "      <td>28.159</td>\n",
       "      <td>001e0610ba46</td>\n",
       "      <td>47.155</td>\n",
       "      <td>-87.627678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.366</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/03/28 19_001e0610ba46</th>\n",
       "      <td>2017/03/28 19</td>\n",
       "      <td>41.878377</td>\n",
       "      <td>1</td>\n",
       "      <td>1.088</td>\n",
       "      <td>28.889</td>\n",
       "      <td>001e0610ba46</td>\n",
       "      <td>45.425</td>\n",
       "      <td>-87.627678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.574</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/03/28 20_001e0610ba46</th>\n",
       "      <td>2017/03/28 20</td>\n",
       "      <td>41.878377</td>\n",
       "      <td>1</td>\n",
       "      <td>0.863</td>\n",
       "      <td>30.430</td>\n",
       "      <td>001e0610ba46</td>\n",
       "      <td>43.239</td>\n",
       "      <td>-87.627678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.016</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/03/28 21_001e0610ba46</th>\n",
       "      <td>2017/03/28 21</td>\n",
       "      <td>41.878377</td>\n",
       "      <td>0</td>\n",
       "      <td>1.250</td>\n",
       "      <td>30.614</td>\n",
       "      <td>001e0610ba46</td>\n",
       "      <td>42.085</td>\n",
       "      <td>-87.627678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.069</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/03/28 22_001e0610ba46</th>\n",
       "      <td>2017/03/28 22</td>\n",
       "      <td>41.878377</td>\n",
       "      <td>1</td>\n",
       "      <td>3.289</td>\n",
       "      <td>30.834</td>\n",
       "      <td>001e0610ba46</td>\n",
       "      <td>41.477</td>\n",
       "      <td>-87.627678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.893</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                timestamp   latitude  label  \\\n",
       "2017/03/28 17_001e0610ba46  2017/03/28 17  41.878377      1   \n",
       "2017/03/28 19_001e0610ba46  2017/03/28 19  41.878377      1   \n",
       "2017/03/28 20_001e0610ba46  2017/03/28 20  41.878377      1   \n",
       "2017/03/28 21_001e0610ba46  2017/03/28 21  41.878377      0   \n",
       "2017/03/28 22_001e0610ba46  2017/03/28 22  41.878377      1   \n",
       "\n",
       "                            tsl250rd_intensity  pr103j2_temperature  \\\n",
       "2017/03/28 17_001e0610ba46               1.639               28.159   \n",
       "2017/03/28 19_001e0610ba46               1.088               28.889   \n",
       "2017/03/28 20_001e0610ba46               0.863               30.430   \n",
       "2017/03/28 21_001e0610ba46               1.250               30.614   \n",
       "2017/03/28 22_001e0610ba46               3.289               30.834   \n",
       "\n",
       "                                 node_id  hih4030_humidity  longitude  \\\n",
       "2017/03/28 17_001e0610ba46  001e0610ba46            47.155 -87.627678   \n",
       "2017/03/28 19_001e0610ba46  001e0610ba46            45.425 -87.627678   \n",
       "2017/03/28 20_001e0610ba46  001e0610ba46            43.239 -87.627678   \n",
       "2017/03/28 21_001e0610ba46  001e0610ba46            42.085 -87.627678   \n",
       "2017/03/28 22_001e0610ba46  001e0610ba46            41.477 -87.627678   \n",
       "\n",
       "                            spv1840lr5h_b_intensity  mlx75305_intensity  ...  \\\n",
       "2017/03/28 17_001e0610ba46                      0.0              37.366  ...   \n",
       "2017/03/28 19_001e0610ba46                      0.0              18.574  ...   \n",
       "2017/03/28 20_001e0610ba46                      0.0              12.016  ...   \n",
       "2017/03/28 21_001e0610ba46                      0.0              14.069  ...   \n",
       "2017/03/28 22_001e0610ba46                      0.0              23.893  ...   \n",
       "\n",
       "                            microphone_octave_6_intensity  \\\n",
       "2017/03/28 17_001e0610ba46                            NaN   \n",
       "2017/03/28 19_001e0610ba46                            NaN   \n",
       "2017/03/28 20_001e0610ba46                            NaN   \n",
       "2017/03/28 21_001e0610ba46                            NaN   \n",
       "2017/03/28 22_001e0610ba46                            NaN   \n",
       "\n",
       "                            microphone_octave_8_intensity  \\\n",
       "2017/03/28 17_001e0610ba46                            NaN   \n",
       "2017/03/28 19_001e0610ba46                            NaN   \n",
       "2017/03/28 20_001e0610ba46                            NaN   \n",
       "2017/03/28 21_001e0610ba46                            NaN   \n",
       "2017/03/28 22_001e0610ba46                            NaN   \n",
       "\n",
       "                            microphone_octave_9_intensity  net_usb_rx  \\\n",
       "2017/03/28 17_001e0610ba46                            NaN         NaN   \n",
       "2017/03/28 19_001e0610ba46                            NaN         NaN   \n",
       "2017/03/28 20_001e0610ba46                            NaN         NaN   \n",
       "2017/03/28 21_001e0610ba46                            NaN         NaN   \n",
       "2017/03/28 22_001e0610ba46                            NaN         NaN   \n",
       "\n",
       "                            microphone_octave_7_intensity  \\\n",
       "2017/03/28 17_001e0610ba46                            NaN   \n",
       "2017/03/28 19_001e0610ba46                            NaN   \n",
       "2017/03/28 20_001e0610ba46                            NaN   \n",
       "2017/03/28 21_001e0610ba46                            NaN   \n",
       "2017/03/28 22_001e0610ba46                            NaN   \n",
       "\n",
       "                            microphone_octave_5_intensity  \\\n",
       "2017/03/28 17_001e0610ba46                            NaN   \n",
       "2017/03/28 19_001e0610ba46                            NaN   \n",
       "2017/03/28 20_001e0610ba46                            NaN   \n",
       "2017/03/28 21_001e0610ba46                            NaN   \n",
       "2017/03/28 22_001e0610ba46                            NaN   \n",
       "\n",
       "                            microphone_octave_3_intensity  \\\n",
       "2017/03/28 17_001e0610ba46                            NaN   \n",
       "2017/03/28 19_001e0610ba46                            NaN   \n",
       "2017/03/28 20_001e0610ba46                            NaN   \n",
       "2017/03/28 21_001e0610ba46                            NaN   \n",
       "2017/03/28 22_001e0610ba46                            NaN   \n",
       "\n",
       "                            microphone_octave_1_intensity  \\\n",
       "2017/03/28 17_001e0610ba46                            NaN   \n",
       "2017/03/28 19_001e0610ba46                            NaN   \n",
       "2017/03/28 20_001e0610ba46                            NaN   \n",
       "2017/03/28 21_001e0610ba46                            NaN   \n",
       "2017/03/28 22_001e0610ba46                            NaN   \n",
       "\n",
       "                            microphone_octave_2_intensity  \\\n",
       "2017/03/28 17_001e0610ba46                            NaN   \n",
       "2017/03/28 19_001e0610ba46                            NaN   \n",
       "2017/03/28 20_001e0610ba46                            NaN   \n",
       "2017/03/28 21_001e0610ba46                            NaN   \n",
       "2017/03/28 22_001e0610ba46                            NaN   \n",
       "\n",
       "                            microphone_octave_10_intensity  \n",
       "2017/03/28 17_001e0610ba46                             NaN  \n",
       "2017/03/28 19_001e0610ba46                             NaN  \n",
       "2017/03/28 20_001e0610ba46                             NaN  \n",
       "2017/03/28 21_001e0610ba46                             NaN  \n",
       "2017/03/28 22_001e0610ba46                             NaN  \n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(labeled_data.shape)\n",
    "labeled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data =labeled_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "136592"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(labeled_data[labeled_data['label']==0]))\n",
    "len(labeled_data[labeled_data['label']==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out the train, dev, and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we want to split the data into training, development, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our X to be all values except the label,timestamp, and node_id as these should be the only non_numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_X = labeled_data.drop(['label','timestamp','node_id'],axis=1)\n",
    "All_y = labeled_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>tsl250rd_intensity</th>\n",
       "      <th>pr103j2_temperature</th>\n",
       "      <th>hih4030_humidity</th>\n",
       "      <th>longitude</th>\n",
       "      <th>spv1840lr5h_b_intensity</th>\n",
       "      <th>mlx75305_intensity</th>\n",
       "      <th>mma8452q_acceleration_z</th>\n",
       "      <th>ml8511_intensity</th>\n",
       "      <th>htu21d_temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>microphone_octave_6_intensity</th>\n",
       "      <th>microphone_octave_8_intensity</th>\n",
       "      <th>microphone_octave_9_intensity</th>\n",
       "      <th>net_usb_rx</th>\n",
       "      <th>microphone_octave_7_intensity</th>\n",
       "      <th>microphone_octave_5_intensity</th>\n",
       "      <th>microphone_octave_3_intensity</th>\n",
       "      <th>microphone_octave_1_intensity</th>\n",
       "      <th>microphone_octave_2_intensity</th>\n",
       "      <th>microphone_octave_10_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017/03/28 17_001e0610ba46</th>\n",
       "      <td>41.878377</td>\n",
       "      <td>1.639</td>\n",
       "      <td>28.159</td>\n",
       "      <td>47.155</td>\n",
       "      <td>-87.627678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.646</td>\n",
       "      <td>27.715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/03/28 19_001e0610ba46</th>\n",
       "      <td>41.878377</td>\n",
       "      <td>1.088</td>\n",
       "      <td>28.889</td>\n",
       "      <td>45.425</td>\n",
       "      <td>-87.627678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.939</td>\n",
       "      <td>28.431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/03/28 20_001e0610ba46</th>\n",
       "      <td>41.878377</td>\n",
       "      <td>0.863</td>\n",
       "      <td>30.430</td>\n",
       "      <td>43.239</td>\n",
       "      <td>-87.627678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.709</td>\n",
       "      <td>29.749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/03/28 21_001e0610ba46</th>\n",
       "      <td>41.878377</td>\n",
       "      <td>1.250</td>\n",
       "      <td>30.614</td>\n",
       "      <td>42.085</td>\n",
       "      <td>-87.627678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.990</td>\n",
       "      <td>29.929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017/03/28 22_001e0610ba46</th>\n",
       "      <td>41.878377</td>\n",
       "      <td>3.289</td>\n",
       "      <td>30.834</td>\n",
       "      <td>41.477</td>\n",
       "      <td>-87.627678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.849</td>\n",
       "      <td>30.135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             latitude  tsl250rd_intensity  \\\n",
       "2017/03/28 17_001e0610ba46  41.878377               1.639   \n",
       "2017/03/28 19_001e0610ba46  41.878377               1.088   \n",
       "2017/03/28 20_001e0610ba46  41.878377               0.863   \n",
       "2017/03/28 21_001e0610ba46  41.878377               1.250   \n",
       "2017/03/28 22_001e0610ba46  41.878377               3.289   \n",
       "\n",
       "                            pr103j2_temperature  hih4030_humidity  longitude  \\\n",
       "2017/03/28 17_001e0610ba46               28.159            47.155 -87.627678   \n",
       "2017/03/28 19_001e0610ba46               28.889            45.425 -87.627678   \n",
       "2017/03/28 20_001e0610ba46               30.430            43.239 -87.627678   \n",
       "2017/03/28 21_001e0610ba46               30.614            42.085 -87.627678   \n",
       "2017/03/28 22_001e0610ba46               30.834            41.477 -87.627678   \n",
       "\n",
       "                            spv1840lr5h_b_intensity  mlx75305_intensity  \\\n",
       "2017/03/28 17_001e0610ba46                      0.0              37.366   \n",
       "2017/03/28 19_001e0610ba46                      0.0              18.574   \n",
       "2017/03/28 20_001e0610ba46                      0.0              12.016   \n",
       "2017/03/28 21_001e0610ba46                      0.0              14.069   \n",
       "2017/03/28 22_001e0610ba46                      0.0              23.893   \n",
       "\n",
       "                            mma8452q_acceleration_z  ml8511_intensity  \\\n",
       "2017/03/28 17_001e0610ba46                      0.0            43.646   \n",
       "2017/03/28 19_001e0610ba46                      0.0            42.939   \n",
       "2017/03/28 20_001e0610ba46                      0.0            41.709   \n",
       "2017/03/28 21_001e0610ba46                      0.0            40.990   \n",
       "2017/03/28 22_001e0610ba46                      0.0            40.849   \n",
       "\n",
       "                            htu21d_temperature  ...  \\\n",
       "2017/03/28 17_001e0610ba46              27.715  ...   \n",
       "2017/03/28 19_001e0610ba46              28.431  ...   \n",
       "2017/03/28 20_001e0610ba46              29.749  ...   \n",
       "2017/03/28 21_001e0610ba46              29.929  ...   \n",
       "2017/03/28 22_001e0610ba46              30.135  ...   \n",
       "\n",
       "                            microphone_octave_6_intensity  \\\n",
       "2017/03/28 17_001e0610ba46                            0.0   \n",
       "2017/03/28 19_001e0610ba46                            0.0   \n",
       "2017/03/28 20_001e0610ba46                            0.0   \n",
       "2017/03/28 21_001e0610ba46                            0.0   \n",
       "2017/03/28 22_001e0610ba46                            0.0   \n",
       "\n",
       "                            microphone_octave_8_intensity  \\\n",
       "2017/03/28 17_001e0610ba46                            0.0   \n",
       "2017/03/28 19_001e0610ba46                            0.0   \n",
       "2017/03/28 20_001e0610ba46                            0.0   \n",
       "2017/03/28 21_001e0610ba46                            0.0   \n",
       "2017/03/28 22_001e0610ba46                            0.0   \n",
       "\n",
       "                            microphone_octave_9_intensity  net_usb_rx  \\\n",
       "2017/03/28 17_001e0610ba46                            0.0         0.0   \n",
       "2017/03/28 19_001e0610ba46                            0.0         0.0   \n",
       "2017/03/28 20_001e0610ba46                            0.0         0.0   \n",
       "2017/03/28 21_001e0610ba46                            0.0         0.0   \n",
       "2017/03/28 22_001e0610ba46                            0.0         0.0   \n",
       "\n",
       "                            microphone_octave_7_intensity  \\\n",
       "2017/03/28 17_001e0610ba46                            0.0   \n",
       "2017/03/28 19_001e0610ba46                            0.0   \n",
       "2017/03/28 20_001e0610ba46                            0.0   \n",
       "2017/03/28 21_001e0610ba46                            0.0   \n",
       "2017/03/28 22_001e0610ba46                            0.0   \n",
       "\n",
       "                            microphone_octave_5_intensity  \\\n",
       "2017/03/28 17_001e0610ba46                            0.0   \n",
       "2017/03/28 19_001e0610ba46                            0.0   \n",
       "2017/03/28 20_001e0610ba46                            0.0   \n",
       "2017/03/28 21_001e0610ba46                            0.0   \n",
       "2017/03/28 22_001e0610ba46                            0.0   \n",
       "\n",
       "                            microphone_octave_3_intensity  \\\n",
       "2017/03/28 17_001e0610ba46                            0.0   \n",
       "2017/03/28 19_001e0610ba46                            0.0   \n",
       "2017/03/28 20_001e0610ba46                            0.0   \n",
       "2017/03/28 21_001e0610ba46                            0.0   \n",
       "2017/03/28 22_001e0610ba46                            0.0   \n",
       "\n",
       "                            microphone_octave_1_intensity  \\\n",
       "2017/03/28 17_001e0610ba46                            0.0   \n",
       "2017/03/28 19_001e0610ba46                            0.0   \n",
       "2017/03/28 20_001e0610ba46                            0.0   \n",
       "2017/03/28 21_001e0610ba46                            0.0   \n",
       "2017/03/28 22_001e0610ba46                            0.0   \n",
       "\n",
       "                            microphone_octave_2_intensity  \\\n",
       "2017/03/28 17_001e0610ba46                            0.0   \n",
       "2017/03/28 19_001e0610ba46                            0.0   \n",
       "2017/03/28 20_001e0610ba46                            0.0   \n",
       "2017/03/28 21_001e0610ba46                            0.0   \n",
       "2017/03/28 22_001e0610ba46                            0.0   \n",
       "\n",
       "                            microphone_octave_10_intensity  \n",
       "2017/03/28 17_001e0610ba46                             0.0  \n",
       "2017/03/28 19_001e0610ba46                             0.0  \n",
       "2017/03/28 20_001e0610ba46                             0.0  \n",
       "2017/03/28 21_001e0610ba46                             0.0  \n",
       "2017/03/28 22_001e0610ba46                             0.0  \n",
       "\n",
       "[5 rows x 142 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017/03/28 17_001e0610ba46    1\n",
       "2017/03/28 19_001e0610ba46    1\n",
       "2017/03/28 20_001e0610ba46    1\n",
       "2017/03/28 21_001e0610ba46    0\n",
       "2017/03/28 22_001e0610ba46    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,X_test,y,y_test=train_test_split(All_X,All_y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now never ever look at X_test and y_test, and will leave them until the very end of the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do also want a development set, so we split again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_dev,y_train,y_dev=train_test_split(X,y,test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (393304, 142) Y_train:  (393304,)\n",
      "X_dev:  (43701, 142) Y_dev:  (43701,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train: ',X_train.shape,'Y_train: ',y_train.shape)\n",
    "print('X_dev: ',X_dev.shape, 'Y_dev: ',y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now we have something we can work with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>tsl250rd_intensity</th>\n",
       "      <th>pr103j2_temperature</th>\n",
       "      <th>hih4030_humidity</th>\n",
       "      <th>longitude</th>\n",
       "      <th>spv1840lr5h_b_intensity</th>\n",
       "      <th>mlx75305_intensity</th>\n",
       "      <th>mma8452q_acceleration_z</th>\n",
       "      <th>ml8511_intensity</th>\n",
       "      <th>htu21d_temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>microphone_octave_6_intensity</th>\n",
       "      <th>microphone_octave_8_intensity</th>\n",
       "      <th>microphone_octave_9_intensity</th>\n",
       "      <th>net_usb_rx</th>\n",
       "      <th>microphone_octave_7_intensity</th>\n",
       "      <th>microphone_octave_5_intensity</th>\n",
       "      <th>microphone_octave_3_intensity</th>\n",
       "      <th>microphone_octave_1_intensity</th>\n",
       "      <th>microphone_octave_2_intensity</th>\n",
       "      <th>microphone_octave_10_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>393304.000000</td>\n",
       "      <td>393304.000000</td>\n",
       "      <td>393304.000000</td>\n",
       "      <td>393304.000000</td>\n",
       "      <td>393304.000000</td>\n",
       "      <td>393304.000000</td>\n",
       "      <td>393304.000000</td>\n",
       "      <td>393304.000000</td>\n",
       "      <td>393304.000000</td>\n",
       "      <td>393304.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.933040e+05</td>\n",
       "      <td>3.933040e+05</td>\n",
       "      <td>3.933040e+05</td>\n",
       "      <td>3.933040e+05</td>\n",
       "      <td>393304.000000</td>\n",
       "      <td>3.933040e+05</td>\n",
       "      <td>3.933040e+05</td>\n",
       "      <td>3.933040e+05</td>\n",
       "      <td>3.933040e+05</td>\n",
       "      <td>393304.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.846957</td>\n",
       "      <td>14.619944</td>\n",
       "      <td>11.377222</td>\n",
       "      <td>70.570331</td>\n",
       "      <td>-87.659522</td>\n",
       "      <td>40.748382</td>\n",
       "      <td>455.059155</td>\n",
       "      <td>1.697578</td>\n",
       "      <td>209.773681</td>\n",
       "      <td>26.063310</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.290171e+32</td>\n",
       "      <td>-2.374399e+32</td>\n",
       "      <td>-2.205548e+32</td>\n",
       "      <td>2.873757e+05</td>\n",
       "      <td>-0.003797</td>\n",
       "      <td>5.165052e+05</td>\n",
       "      <td>1.033222e+06</td>\n",
       "      <td>-5.177602e+05</td>\n",
       "      <td>1.169906e+06</td>\n",
       "      <td>-0.014686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.077617</td>\n",
       "      <td>16.318736</td>\n",
       "      <td>13.915346</td>\n",
       "      <td>22.178959</td>\n",
       "      <td>0.054524</td>\n",
       "      <td>27.995619</td>\n",
       "      <td>502.470859</td>\n",
       "      <td>68.010812</td>\n",
       "      <td>385.657505</td>\n",
       "      <td>41.522349</td>\n",
       "      <td>...</td>\n",
       "      <td>1.436257e+35</td>\n",
       "      <td>1.489079e+35</td>\n",
       "      <td>1.383187e+35</td>\n",
       "      <td>2.969575e+07</td>\n",
       "      <td>2.420317</td>\n",
       "      <td>3.239208e+08</td>\n",
       "      <td>6.478950e+08</td>\n",
       "      <td>3.247870e+08</td>\n",
       "      <td>7.338097e+08</td>\n",
       "      <td>9.210395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>41.666078</td>\n",
       "      <td>-0.071000</td>\n",
       "      <td>-54.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-87.982901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13.191000</td>\n",
       "      <td>-1648.438000</td>\n",
       "      <td>-143.631000</td>\n",
       "      <td>-124.868000</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.007336e+37</td>\n",
       "      <td>-9.338605e+37</td>\n",
       "      <td>-8.674510e+37</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1517.678000</td>\n",
       "      <td>-8.900000e-02</td>\n",
       "      <td>-8.900000e-02</td>\n",
       "      <td>-2.036868e+11</td>\n",
       "      <td>-1.113083e+08</td>\n",
       "      <td>-5776.203000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41.788430</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>1.918000</td>\n",
       "      <td>66.766000</td>\n",
       "      <td>-87.683048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.883000</td>\n",
       "      <td>-0.977000</td>\n",
       "      <td>42.457000</td>\n",
       "      <td>1.583000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>41.857797</td>\n",
       "      <td>1.784000</td>\n",
       "      <td>10.106000</td>\n",
       "      <td>76.229000</td>\n",
       "      <td>-87.665685</td>\n",
       "      <td>56.513000</td>\n",
       "      <td>330.471000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.785000</td>\n",
       "      <td>11.849500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41.912681</td>\n",
       "      <td>34.541000</td>\n",
       "      <td>23.312000</td>\n",
       "      <td>83.032250</td>\n",
       "      <td>-87.624179</td>\n",
       "      <td>58.977000</td>\n",
       "      <td>687.858000</td>\n",
       "      <td>15.208000</td>\n",
       "      <td>52.005000</td>\n",
       "      <td>26.850000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41.994597</td>\n",
       "      <td>159.907000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>154.210000</td>\n",
       "      <td>-87.536509</td>\n",
       "      <td>104.850000</td>\n",
       "      <td>1449.643000</td>\n",
       "      <td>108.793000</td>\n",
       "      <td>1135.624000</td>\n",
       "      <td>128.860000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.400000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.400000e-02</td>\n",
       "      <td>5.456206e+09</td>\n",
       "      <td>24.530000</td>\n",
       "      <td>2.031435e+11</td>\n",
       "      <td>4.063206e+11</td>\n",
       "      <td>4.960021e+07</td>\n",
       "      <td>4.602010e+11</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            latitude  tsl250rd_intensity  pr103j2_temperature  \\\n",
       "count  393304.000000       393304.000000        393304.000000   \n",
       "mean       41.846957           14.619944            11.377222   \n",
       "std         0.077617           16.318736            13.915346   \n",
       "min        41.666078           -0.071000           -54.900000   \n",
       "25%        41.788430            0.075000             1.918000   \n",
       "50%        41.857797            1.784000            10.106000   \n",
       "75%        41.912681           34.541000            23.312000   \n",
       "max        41.994597          159.907000            80.000000   \n",
       "\n",
       "       hih4030_humidity      longitude  spv1840lr5h_b_intensity  \\\n",
       "count     393304.000000  393304.000000            393304.000000   \n",
       "mean          70.570331     -87.659522                40.748382   \n",
       "std           22.178959       0.054524                27.995619   \n",
       "min            0.000000     -87.982901                 0.000000   \n",
       "25%           66.766000     -87.683048                 0.000000   \n",
       "50%           76.229000     -87.665685                56.513000   \n",
       "75%           83.032250     -87.624179                58.977000   \n",
       "max          154.210000     -87.536509               104.850000   \n",
       "\n",
       "       mlx75305_intensity  mma8452q_acceleration_z  ml8511_intensity  \\\n",
       "count       393304.000000            393304.000000     393304.000000   \n",
       "mean           455.059155                 1.697578        209.773681   \n",
       "std            502.470859                68.010812        385.657505   \n",
       "min            -13.191000             -1648.438000       -143.631000   \n",
       "25%              1.883000                -0.977000         42.457000   \n",
       "50%            330.471000                 0.000000         45.785000   \n",
       "75%            687.858000                15.208000         52.005000   \n",
       "max           1449.643000               108.793000       1135.624000   \n",
       "\n",
       "       htu21d_temperature  ...  microphone_octave_6_intensity  \\\n",
       "count       393304.000000  ...                   3.933040e+05   \n",
       "mean            26.063310  ...                  -2.290171e+32   \n",
       "std             41.522349  ...                   1.436257e+35   \n",
       "min           -124.868000  ...                  -9.007336e+37   \n",
       "25%              1.583000  ...                   0.000000e+00   \n",
       "50%             11.849500  ...                   0.000000e+00   \n",
       "75%             26.850000  ...                   0.000000e+00   \n",
       "max            128.860000  ...                   4.400000e-02   \n",
       "\n",
       "       microphone_octave_8_intensity  microphone_octave_9_intensity  \\\n",
       "count                   3.933040e+05                   3.933040e+05   \n",
       "mean                   -2.374399e+32                  -2.205548e+32   \n",
       "std                     1.489079e+35                   1.383187e+35   \n",
       "min                    -9.338605e+37                  -8.674510e+37   \n",
       "25%                     0.000000e+00                   0.000000e+00   \n",
       "50%                     0.000000e+00                   0.000000e+00   \n",
       "75%                     0.000000e+00                   0.000000e+00   \n",
       "max                     0.000000e+00                   4.400000e-02   \n",
       "\n",
       "         net_usb_rx  microphone_octave_7_intensity  \\\n",
       "count  3.933040e+05                  393304.000000   \n",
       "mean   2.873757e+05                      -0.003797   \n",
       "std    2.969575e+07                       2.420317   \n",
       "min    0.000000e+00                   -1517.678000   \n",
       "25%    0.000000e+00                       0.000000   \n",
       "50%    0.000000e+00                       0.000000   \n",
       "75%    0.000000e+00                       0.000000   \n",
       "max    5.456206e+09                      24.530000   \n",
       "\n",
       "       microphone_octave_5_intensity  microphone_octave_3_intensity  \\\n",
       "count                   3.933040e+05                   3.933040e+05   \n",
       "mean                    5.165052e+05                   1.033222e+06   \n",
       "std                     3.239208e+08                   6.478950e+08   \n",
       "min                    -8.900000e-02                  -8.900000e-02   \n",
       "25%                     0.000000e+00                   0.000000e+00   \n",
       "50%                     0.000000e+00                   0.000000e+00   \n",
       "75%                     0.000000e+00                   0.000000e+00   \n",
       "max                     2.031435e+11                   4.063206e+11   \n",
       "\n",
       "       microphone_octave_1_intensity  microphone_octave_2_intensity  \\\n",
       "count                   3.933040e+05                   3.933040e+05   \n",
       "mean                   -5.177602e+05                   1.169906e+06   \n",
       "std                     3.247870e+08                   7.338097e+08   \n",
       "min                    -2.036868e+11                  -1.113083e+08   \n",
       "25%                     0.000000e+00                   0.000000e+00   \n",
       "50%                     0.000000e+00                   0.000000e+00   \n",
       "75%                     0.000000e+00                   0.000000e+00   \n",
       "max                     4.960021e+07                   4.602010e+11   \n",
       "\n",
       "       microphone_octave_10_intensity  \n",
       "count                   393304.000000  \n",
       "mean                        -0.014686  \n",
       "std                          9.210395  \n",
       "min                      -5776.203000  \n",
       "25%                          0.000000  \n",
       "50%                          0.000000  \n",
       "75%                          0.000000  \n",
       "max                          0.000000  \n",
       "\n",
       "[8 rows x 142 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train_scaled = StandardScaler().fit_transform(X_train)\n",
    "X_dev_scaled = StandardScaler().fit_transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98496 294808\n"
     ]
    }
   ],
   "source": [
    "print(len([x for x in y_train if x==1]), len([x for x in y_train if x==0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jyckle/ws/chicago/env/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#clf = LogisticRegression(C=0.001,random_state=0, solver='lbfgs',max_iter=1000)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With many models ahead, a function to evaluate our models is extremely helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(clf):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import recall_score\n",
    "    from sklearn.metrics import precision_score\n",
    "\n",
    "    y_train_pred=clf.predict(X_train_scaled)\n",
    "    y_dev_pred=clf.predict(X_dev_scaled)\n",
    "\n",
    "    print('train_acc: ', accuracy_score(y_train,y_train_pred),'dev_acc: ', accuracy_score(y_dev,y_dev_pred), '\\n',\n",
    "          'train_rec: ',recall_score(y_train,y_train_pred),'dev_rec: ',recall_score(y_dev,y_dev_pred), '\\n',\n",
    "          'train_pre: ',precision_score(y_train,y_train_pred),'dev_pre: ',precision_score(y_dev,y_dev_pred))  \n",
    "    return (y_train_pred,y_dev_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc:  0.7488202510017696 dev_acc:  0.7450859248072127 \n",
      " train_rec:  0.022742040285899934 dev_rec:  0.03306531755352787 \n",
      " train_pre:  0.46920821114369504 dev_pre:  0.45579078455790784\n"
     ]
    }
   ],
   "source": [
    "y_train_pred, y_dev_pred= evaluate_model(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train examples:  393304 \n",
      " predicted positive train examples:  4774 \n",
      " actual positive train examples:  98496\n"
     ]
    }
   ],
   "source": [
    "print('total train examples: ', len(y_train_pred), '\\n',\n",
    "      'predicted positive train examples: ',len([y for y in y_train_pred if y >0.5]), '\\n',\n",
    "     'actual positive train examples: ',len([y for y in y_train if y >0.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how a decision tree classifier does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc:  0.9991787523137319 dev_acc:  0.6056154321411409 \n",
      " train_rec:  0.9967511371020142 dev_rec:  0.42894570421899 \n",
      " train_pre:  0.9999694435673616 dev_pre:  0.30315413101774996\n"
     ]
    }
   ],
   "source": [
    "y_train_pred, y_dev_pred= evaluate_model(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train examples:  393304 \n",
      " predicted positive train examples:  98179 \n",
      " actual positive train examples:  98496\n"
     ]
    }
   ],
   "source": [
    "print('total train examples: ', len(y_train_pred), '\\n',\n",
    "      'predicted positive train examples: ',len([y for y in y_train_pred if y >0.5]), '\\n',\n",
    "     'actual positive train examples: ',len([y for y in y_train if y >0.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly overfitting, so let's add some regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0,max_depth=10)\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc:  0.7611542216707686 dev_acc:  0.7462071806137159 \n",
      " train_rec:  0.20025178687459388 dev_rec:  0.18583431204264161 \n",
      " train_pre:  0.5653033733627583 dev_pre:  0.4973404255319149\n"
     ]
    }
   ],
   "source": [
    "y_train_pred, y_dev_pred= evaluate_model(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train examples:  393304 \n",
      " predicted positive train examples:  34891 \n",
      " actual positive train examples:  98496\n"
     ]
    }
   ],
   "source": [
    "print('total train examples: ', len(y_train_pred), '\\n',\n",
    "      'predicted positive train examples: ',len([y for y in y_train_pred if y >0.5]), '\\n',\n",
    "     'actual positive train examples: ',len([y for y in y_train if y >0.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! Overfitting was fixed, but now we're back to a pretty low recall. let's see if we can get away with any less regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=15,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0,max_depth=15)\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc:  0.7851992351972011 dev_acc:  0.7280382599940505 \n",
      " train_rec:  0.27014294996751137 dev_rec:  0.22919866293251423 \n",
      " train_pre:  0.678740880567318 dev_pre:  0.4307300509337861\n"
     ]
    }
   ],
   "source": [
    "y_train_pred, y_dev_pred= evaluate_model(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train examples:  393304 \n",
      " predicted positive train examples:  39202 \n",
      " actual positive train examples:  98496\n"
     ]
    }
   ],
   "source": [
    "print('total train examples: ', len(y_train_pred), '\\n',\n",
    "      'predicted positive train examples: ',len([y for y in y_train_pred if y >0.5]), '\\n',\n",
    "     'actual positive train examples: ',len([y for y in y_train if y >0.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that didn't help. Let's try a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100,max_depth=10,random_state=0)\n",
    "clf.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc:  0.753646034619531 dev_acc:  0.7489531132010709 \n",
      " train_rec:  0.03190992527615335 dev_rec:  0.02249525702412142 \n",
      " train_pre:  0.6712943186672362 dev_pre:  0.6225\n"
     ]
    }
   ],
   "source": [
    "y_train_pred, y_dev_pred= evaluate_model(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train examples:  393304 \n",
      " predicted positive train examples:  4682 \n",
      " actual positive train examples:  98496\n"
     ]
    }
   ],
   "source": [
    "print('total train examples: ', len(y_train_pred), '\\n',\n",
    "      'predicted positive train examples: ',len([y for y in y_train_pred if y >0.5]), '\\n',\n",
    "     'actual positive train examples: ',len([y for y in y_train if y >0.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "keras_model = Sequential()\n",
    "keras_model.add(Dense(10, input_shape = (len(X_train_scaled[0]),),activation='relu'))\n",
    "keras_model.add(Dense(10, activation='relu'))\n",
    "keras_model.add(Dense(1, activation='sigmoid'))\n",
    "keras_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 393304 samples, validate on 43701 samples\n",
      "Epoch 1/5\n",
      "393304/393304 [==============================] - 16s 40us/step - loss: 0.5241 - acc: 0.7505 - val_loss: 0.5224 - val_acc: 0.7486\n",
      "Epoch 2/5\n",
      "393304/393304 [==============================] - 16s 40us/step - loss: 0.5143 - acc: 0.7531 - val_loss: 0.5190 - val_acc: 0.7514\n",
      "Epoch 3/5\n",
      "393304/393304 [==============================] - 15s 39us/step - loss: 0.5116 - acc: 0.7539 - val_loss: 0.5185 - val_acc: 0.7517\n",
      "Epoch 4/5\n",
      "393304/393304 [==============================] - 15s 39us/step - loss: 0.5105 - acc: 0.7542 - val_loss: 0.5154 - val_acc: 0.7523\n",
      "Epoch 5/5\n",
      "393304/393304 [==============================] - 15s 39us/step - loss: 0.5091 - acc: 0.7548 - val_loss: 0.5162 - val_acc: 0.7520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f407d528320>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model.fit(X_train_scaled, y_train, epochs=5,validation_data=(X_dev_scaled,y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred =keras_model.predict_classes(X_train_scaled)\n",
    "y_dev_pred = keras_model.predict_classes(X_dev_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc:  0.7542104834936842 dev_acc:  0.7519507562756002 \n",
      " train_rec:  0.08778021442495126 dev_rec:  0.08257295148613245 \n",
      " train_pre:  0.5590327169274538 dev_pre:  0.5716072545340838\n"
     ]
    }
   ],
   "source": [
    "print('train_acc: ', accuracy_score(y_train,y_train_pred),'dev_acc: ', accuracy_score(y_dev,y_dev_pred), '\\n',\n",
    "          'train_rec: ',recall_score(y_train,y_train_pred),'dev_rec: ',recall_score(y_dev,y_dev_pred), '\\n',\n",
    "          'train_pre: ',precision_score(y_train,y_train_pred),'dev_pre: ',precision_score(y_dev,y_dev_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if a different loss function helps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "keras_model = Sequential()\n",
    "keras_model.add(Dense(10, input_shape = (len(X_train_scaled[0]),),activation='relu'))\n",
    "keras_model.add(Dense(10, activation='relu'))\n",
    "keras_model.add(Dense(1, activation='sigmoid'))\n",
    "keras_model.compile(loss='mean_squared_error',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 393304 samples, validate on 43701 samples\n",
      "Epoch 1/5\n",
      "393304/393304 [==============================] - 15s 38us/step - loss: 0.1743 - acc: 0.7515 - val_loss: 0.1730 - val_acc: 0.7522\n",
      "Epoch 2/5\n",
      "393304/393304 [==============================] - 15s 37us/step - loss: 0.1702 - acc: 0.7553 - val_loss: 0.1718 - val_acc: 0.7536\n",
      "Epoch 3/5\n",
      "393304/393304 [==============================] - 15s 37us/step - loss: 0.1693 - acc: 0.7564 - val_loss: 0.1714 - val_acc: 0.7532\n",
      "Epoch 4/5\n",
      "393304/393304 [==============================] - 15s 37us/step - loss: 0.1689 - acc: 0.7568 - val_loss: 0.1711 - val_acc: 0.7542\n",
      "Epoch 5/5\n",
      "393304/393304 [==============================] - 15s 38us/step - loss: 0.1686 - acc: 0.7572 - val_loss: 0.1715 - val_acc: 0.7550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4105e0d390>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model.fit(X_train_scaled, y_train, epochs=5,validation_data=(X_dev_scaled,y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred =keras_model.predict_classes(X_train_scaled)\n",
    "y_dev_pred = keras_model.predict_classes(X_dev_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc:  0.7574725911762911 dev_acc:  0.7549712821216906 \n",
      " train_rec:  0.13067535737491878 dev_rec:  0.12720209594362633 \n",
      " train_pre:  0.5686828966553263 dev_pre:  0.5735234215885947\n"
     ]
    }
   ],
   "source": [
    "print('train_acc: ', accuracy_score(y_train,y_train_pred),'dev_acc: ', accuracy_score(y_dev,y_dev_pred), '\\n',\n",
    "          'train_rec: ',recall_score(y_train,y_train_pred),'dev_rec: ',recall_score(y_dev,y_dev_pred), '\\n',\n",
    "          'train_pre: ',precision_score(y_train,y_train_pred),'dev_pre: ',precision_score(y_dev,y_dev_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a great boost in recall performance so let's try another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "keras_model = Sequential()\n",
    "keras_model.add(Dense(10, input_shape = (len(X_train_scaled[0]),),activation='relu'))\n",
    "keras_model.add(Dense(10, activation='relu'))\n",
    "keras_model.add(Dense(1, activation='sigmoid'))\n",
    "keras_model.compile(loss='squared_hinge',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 393304 samples, validate on 43701 samples\n",
      "Epoch 1/5\n",
      "393304/393304 [==============================] - 15s 38us/step - loss: 0.7497 - acc: 0.2505 - val_loss: 0.7467 - val_acc: 0.2533\n",
      "Epoch 2/5\n",
      "393304/393304 [==============================] - 15s 38us/step - loss: 0.7496 - acc: 0.2504 - val_loss: 0.7467 - val_acc: 0.2533\n",
      "Epoch 3/5\n",
      "393304/393304 [==============================] - 15s 38us/step - loss: 0.7496 - acc: 0.2504 - val_loss: 0.7467 - val_acc: 0.2533\n",
      "Epoch 4/5\n",
      "393304/393304 [==============================] - 15s 38us/step - loss: 0.7496 - acc: 0.2504 - val_loss: 0.7467 - val_acc: 0.2533\n",
      "Epoch 5/5\n",
      "393304/393304 [==============================] - 15s 38us/step - loss: 0.7496 - acc: 0.2504 - val_loss: 0.7467 - val_acc: 0.2533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f407f2ba710>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model.fit(X_train_scaled, y_train, epochs=5,validation_data=(X_dev_scaled,y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred =keras_model.predict_classes(X_train_scaled)\n",
    "y_dev_pred = keras_model.predict_classes(X_dev_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc:  0.25043223562435163 dev_acc:  0.25328939841193565 \n",
      " train_rec:  1.0 dev_rec:  1.0 \n",
      " train_pre:  0.25043223562435163 dev_pre:  0.25328939841193565\n"
     ]
    }
   ],
   "source": [
    "print('train_acc: ', accuracy_score(y_train,y_train_pred),'dev_acc: ', accuracy_score(y_dev,y_dev_pred), '\\n',\n",
    "          'train_rec: ',recall_score(y_train,y_train_pred),'dev_rec: ',recall_score(y_dev,y_dev_pred), '\\n',\n",
    "          'train_pre: ',precision_score(y_train,y_train_pred),'dev_pre: ',precision_score(y_dev,y_dev_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train examples:  393304 \n",
      " predicted positive train examples:  393304 \n",
      " actual positive train examples:  98496\n"
     ]
    }
   ],
   "source": [
    "print('total train examples: ', len(y_train_pred), '\\n',\n",
    "      'predicted positive train examples: ',len([y for y in y_train_pred if y >0.5]), '\\n',\n",
    "     'actual positive train examples: ',len([y for y in y_train if y >0.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate our mean_squared_error neural network on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc:  0.760050159264819 \n",
      " test_rec:  0.12857512857512857 \n",
      " test_pre:  0.5661453242098403\n"
     ]
    }
   ],
   "source": [
    "X_test_scaled = StandardScaler().fit_transform(X_test)\n",
    "y_test_pred= keras_model.predict_classes(X_test_scaled)\n",
    "print('test_acc: ', accuracy_score(y_test,y_test_pred), '\\n',\n",
    "          'test_rec: ',recall_score(y_test,y_test_pred), '\\n',\n",
    "          'test_pre: ',precision_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO-DO\n",
    "* Look at what the best options for increasing recall are\n",
    "* look at what other steps might be taken to modify the data in preprocessing\n",
    "* find a balanced model\n",
    "* evaluate all on the test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
